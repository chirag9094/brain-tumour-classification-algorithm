{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"monai-weekly[gdown, nibabel, tqdm, itk]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    EnsureChannelFirst,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    ToTensor,\n",
    ")\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'C:\\Users\\Chirag C\\vit\\docs\\medi-scan\\archive'\n",
    "class_names = sorted([x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x))])\n",
    "num_class = len(class_names)\n",
    "image_files = [[os.path.join(data_dir, class_name, x)\n",
    "                for x in os.listdir(os.path.join(data_dir, class_name))]\n",
    "               for class_name in class_names]\n",
    "image_file_list = []\n",
    "image_label_list = []\n",
    "for i, class_name in enumerate(class_names):\n",
    "    image_file_list.extend(image_files[i])\n",
    "    image_label_list.extend([i] * len(image_files[i]))\n",
    "for i in range(len(image_file_list)):\n",
    "    cat = cv2.imread(image_file_list[i])\n",
    "    width, height = int(500), int(500)\n",
    "    resized_cat = cv2.resize(cat, (width, height), interpolation = cv2.INTER_AREA,)\n",
    "    #print(resized_cat.shape[1],resized_cat.shape[0])\n",
    "    cv2.imwrite(image_file_list[i], resized_cat)\n",
    "\n",
    "num_total = len(image_label_list)\n",
    "image_width, image_height = Image.open(image_file_list[504]).size\n",
    "\n",
    "print('Total image count:', num_total)\n",
    "print(\"Image dimensions:\", image_width, \"x\", image_height)\n",
    "print(\"Label names:\", class_names)\n",
    "print(\"Label counts:\", [len(image_files[i]) for i in range(num_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(3, 3, figsize=(8, 8))\n",
    "for i,k in enumerate(np.random.randint(num_total, size=9)):\n",
    "    im = Image.open(image_file_list[k])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.xlabel(class_names[image_label_list[k]])\n",
    "    plt.imshow(arr, cmap='gray', vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_frac, test_frac = 0.1, 0.1\n",
    "trainX, trainY = [], []\n",
    "valX, valY = [], []\n",
    "testX, testY = [], []\n",
    "\n",
    "for i in range(num_total):\n",
    "    rann = np.random.random()\n",
    "    if rann < valid_frac:\n",
    "        valX.append(image_file_list[i])\n",
    "        valY.append(image_label_list[i])\n",
    "    elif rann < test_frac + valid_frac:\n",
    "        testX.append(image_file_list[i])\n",
    "        testY.append(image_label_list[i])\n",
    "    else:\n",
    "        trainX.append(image_file_list[i])\n",
    "        trainY.append(image_label_list[i])\n",
    "\n",
    "print(\"Training count =\",len(trainX),\"Validation count =\", len(valX), \"Test count =\",len(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    EnsureChannelFirst(),\n",
    "    ScaleIntensity(),\n",
    "    RandRotate(range_x=15, prob=0.5, keep_size=True),\n",
    "    RandFlip(spatial_axis=0, prob=0.5),\n",
    "    RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5, keep_size=True),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    EnsureChannelFirst(),\n",
    "    ScaleIntensity(),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "act = Activations(softmax=True)\n",
    "to_onehot = AsDiscrete(to_onehot=num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scann(Dataset):\n",
    "    \n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        # self.batch_size = 100\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "train_ds = Scann(trainX, trainY, train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=10, shuffle=True)\n",
    "\n",
    "val_ds = Scann(valX, valY, val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=10)\n",
    "\n",
    "test_ds = Scann(testX, testY, val_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = DenseNet121(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=num_class\n",
    ").to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
    "epoch_num = 30\n",
    "val_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "auc_metric = ROCAUCMetric()\n",
    "metric_values = list()\n",
    "for epoch in range(epoch_num):\n",
    "    print('-' * 10)\n",
    "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "            y = torch.tensor([], dtype=torch.long, device=device)\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
    "                y = torch.cat([y, val_labels], dim=0)\n",
    "            y_onehot = [to_onehot(i) for i in y]\n",
    "            y_pred_act = [act(i) for i in y_pred]\n",
    "            auc_metric(y_pred_act, y_onehot)\n",
    "            auc_result = auc_metric.aggregate()\n",
    "            auc_metric.reset()\n",
    "            del y_pred_act, y_onehot\n",
    "            metric_values.append(auc_result)\n",
    "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
    "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
    "            if acc_metric > best_metric:\n",
    "                best_metric = acc_metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
    "                print('saved new best metric model')\n",
    "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
    "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
    "                  f\" at epoch: {best_metric_epoch}\")\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values_val = list()\n",
    "auc_metric = ROCAUCMetric()\n",
    "metric_values_val = list()\n",
    "model.eval()\n",
    "for epoch in range(epoch_num):\n",
    "    print('-' * 10)\n",
    "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in val_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(val_ds) // val_loader.batch_size}, val_loss: {loss.item():.4f}\")\n",
    "        epoch_len = len(val_ds) // val_loader.batch_size\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values_val.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "            y = torch.tensor([], dtype=torch.long, device=device)\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
    "                y = torch.cat([y, val_labels], dim=0)\n",
    "            y_onehot = [to_onehot(i) for i in y]\n",
    "            y_pred_act = [act(i) for i in y_pred]\n",
    "            auc_metric(y_pred_act, y_onehot)\n",
    "            auc_result = auc_metric.aggregate()\n",
    "            auc_metric.reset()\n",
    "            del y_pred_act, y_onehot\n",
    "            metric_values_val.append(auc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_metric_model.pth'))\n",
    "model.eval()\n",
    "y_true = list()\n",
    "y_pred = list()\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "        pred = model(test_images).argmax(dim=1)\n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(test_ds))\n",
    "print(len(y_pred))\n",
    "plt.subplots(3, 3, figsize=(8, 8))\n",
    "for i,k in enumerate(np.random.randint(len(y_pred), size=9)):\n",
    "    im = Image.open(testX[k])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.xlabel(class_names[testY[k]]+\" / \"+class_names[y_pred[k]])\n",
    "    plt.imshow(arr, cmap='gray', vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "model.eval()\n",
    "h = 0\n",
    "res = []\n",
    "test_ds = Scann(testX, testY, val_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1)\n",
    "for batch_data in test_loader:\n",
    "    inputs = batch_data[0].to(device)\n",
    "    outputs = model(inputs)\n",
    "    y_scores = F.softmax(outputs, dim=1)\n",
    "    numpy_array = y_scores[0].cpu().detach().numpy()\n",
    "    numpy_array = np.around(numpy_array, decimals=1)\n",
    "    res.append(numpy_array)\n",
    "    h = h + 1\n",
    "res = np.vstack(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "y_true11 = y_true\n",
    "y_scores11 = res\n",
    "n_classes = y_scores11.shape[1]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true11, y_scores11[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "for i, model_name in enumerate(class_names):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true11, y_scores11[:, i], pos_label=i)\n",
    "    roc_auc = auc(fpr[i], tpr[i])\n",
    "    plt.plot(fpr[i], tpr[i], label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "plt.plot(x1,metric_values, label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "x1 = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y1 = epoch_loss_values\n",
    "plt.figure()\n",
    "plt.plot(x1, y1, color='r',label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "plt.plot(x1,metric_values, label='Training Accuracy')\n",
    "plt.plot(x1,metric_values_val, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0.885, 1.001])\n",
    "plt.xticks(range(0, 22, 2))\n",
    "plt.xlim([0, 20])\n",
    "\n",
    "plt.show()\n",
    "x1 = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y1 = epoch_loss_values\n",
    "y2 = epoch_loss_values_val\n",
    "plt.figure()\n",
    "plt.plot(x1, y1, color='r',label='Training Loss')\n",
    "plt.plot(x1, y2, color='g',label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(range(0, 22, 2))\n",
    "plt.xlim([0, 20])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat = tf.math.confusion_matrix(labels=y_true, predictions=y_pred).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = class_names,\n",
    "                     columns = class_names)\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('medi_scan_brain.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
